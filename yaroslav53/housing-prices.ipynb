{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"},{"sourceId":6974528,"sourceType":"datasetVersion","datasetId":4007572}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\nfrom sklearn.metrics import make_scorer, mean_squared_log_error\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import IsolationForest\nfrom xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:24.13366Z","iopub.execute_input":"2023-12-17T17:19:24.134076Z","iopub.status.idle":"2023-12-17T17:19:24.152109Z","shell.execute_reply.started":"2023-12-17T17:19:24.134041Z","shell.execute_reply":"2023-12-17T17:19:24.150795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv')\ndf_train = df_train.drop(['Id'], axis=1)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:24.396763Z","iopub.execute_input":"2023-12-17T17:19:24.397154Z","iopub.status.idle":"2023-12-17T17:19:24.460943Z","shell.execute_reply.started":"2023-12-17T17:19:24.397123Z","shell.execute_reply":"2023-12-17T17:19:24.460036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv')\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:24.563615Z","iopub.execute_input":"2023-12-17T17:19:24.564425Z","iopub.status.idle":"2023-12-17T17:19:24.621879Z","shell.execute_reply.started":"2023-12-17T17:19:24.564387Z","shell.execute_reply":"2023-12-17T17:19:24.620833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cat /kaggle/input/home-data-for-ml-course/data_description.txt","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:24.713644Z","iopub.execute_input":"2023-12-17T17:19:24.714055Z","iopub.status.idle":"2023-12-17T17:19:25.834824Z","shell.execute_reply.started":"2023-12-17T17:19:24.714022Z","shell.execute_reply":"2023-12-17T17:19:25.83356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preliminary Data Analysis","metadata":{}},{"cell_type":"markdown","source":"This part is optional; here, I decided to preliminarily examine the features that appear suspicious","metadata":{}},{"cell_type":"code","source":"# Let's examine the number of filled values in the columns.\n\ndf_train.describe().iloc[0].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:25.837065Z","iopub.execute_input":"2023-12-17T17:19:25.838279Z","iopub.status.idle":"2023-12-17T17:19:25.930662Z","shell.execute_reply.started":"2023-12-17T17:19:25.838238Z","shell.execute_reply":"2023-12-17T17:19:25.929387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's examine the number of filled values in the columns.\n\ndf_train.describe(include=object).iloc[0].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:25.932174Z","iopub.execute_input":"2023-12-17T17:19:25.932596Z","iopub.status.idle":"2023-12-17T17:19:26.018246Z","shell.execute_reply.started":"2023-12-17T17:19:25.932565Z","shell.execute_reply":"2023-12-17T17:19:26.016982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieving feature names with a high number of missing values.\n\nunique_counts = df_train.describe(include='object').iloc[0]\nmissing_data_columns = unique_counts[unique_counts <= 800].index.tolist()\nmissing_data_columns","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:26.023368Z","iopub.execute_input":"2023-12-17T17:19:26.023749Z","iopub.status.idle":"2023-12-17T17:19:26.257735Z","shell.execute_reply.started":"2023-12-17T17:19:26.023718Z","shell.execute_reply":"2023-12-17T17:19:26.25659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identifying features with suspiciously low variability for further inspection.\n\nsuspicious_low_variability_features = [col for col in df_train.columns.to_list() \n if df_train[col].value_counts().iloc[0] >= sum(~(df_train[col].isna())) * 0.7 \n and df_train[col].value_counts().iloc[1] < sum(~(df_train[col].isna())) * 0.2]\n\nfor name_col in suspicious_low_variability_features:\n    if name_col in missing_data_columns:\n        suspicious_low_variability_features.remove(name_col)\n        \nsuspicious_low_variability_features","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:26.259251Z","iopub.execute_input":"2023-12-17T17:19:26.259591Z","iopub.status.idle":"2023-12-17T17:19:26.383957Z","shell.execute_reply.started":"2023-12-17T17:19:26.259563Z","shell.execute_reply":"2023-12-17T17:19:26.382676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization #1","metadata":{}},{"cell_type":"code","source":"# Replacing NaN for visualization.\n\ndf_train_copy = df_train.copy()\n\ncolumns_to_fill = {\n    'Alley': 'No alley access',\n    'MasVnrType': 'No Masonry',\n    'FireplaceQu': 'No Fireplace',\n    'PoolQC': 'No Pool',\n    'Fence': 'No Fence',\n    'MiscFeature': 'No feature',\n    'GarageQual': 'No Garage',\n    'GarageCond': 'No Garage',\n    'BsmtCond': 'No Basement',\n    'BsmtFinType2': 'No Basement'\n}\n\nfor column, value in columns_to_fill.items():\n    df_train_copy[column] = df_train_copy[column].fillna(value)\n    \n# Checking the number of missing values in the features I will be visualizing.\ndf_train_copy[suspicious_low_variability_features + missing_data_columns].isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:26.385229Z","iopub.execute_input":"2023-12-17T17:19:26.385551Z","iopub.status.idle":"2023-12-17T17:19:26.417661Z","shell.execute_reply.started":"2023-12-17T17:19:26.385523Z","shell.execute_reply":"2023-12-17T17:19:26.416425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in missing_data_columns:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n    \n    # Countplot: Display the number of samples for each category. \n    sns.countplot(x=col, data=df_train_copy, ax=axes[0])\n    axes[0].set_title(f'Countplot of {col}')\n    \n    # Barplot: Display the average SalePrice for each category. \n    sns.barplot(x=col, y='SalePrice', data=df_train_copy, ax=axes[1])\n    axes[1].set_title(f'Barplot of {col} vs SalePrice')\n    \n    # Boxplot: Display the SalePrice distribution for each category. \n    sns.boxplot(x=col, y='SalePrice', data=df_train_copy, ax=axes[2])\n    axes[2].set_title(f'Boxplot of {col} vs SalePrice')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:26.419248Z","iopub.execute_input":"2023-12-17T17:19:26.419795Z","iopub.status.idle":"2023-12-17T17:19:33.030097Z","shell.execute_reply.started":"2023-12-17T17:19:26.419751Z","shell.execute_reply":"2023-12-17T17:19:33.028936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting columns into numerical and categorical for visualization.\n\nsuspicious_low_variability_features_numeric = df_train_copy[suspicious_low_variability_features].select_dtypes(include=['int64', 'float64'])\n\nsuspicious_low_variability_features_categ = df_train_copy[suspicious_low_variability_features].select_dtypes(include=['object'])\n\nsuspicious_low_variability_features_numeric.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:33.03336Z","iopub.execute_input":"2023-12-17T17:19:33.033725Z","iopub.status.idle":"2023-12-17T17:19:33.080986Z","shell.execute_reply.started":"2023-12-17T17:19:33.033693Z","shell.execute_reply":"2023-12-17T17:19:33.079773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in (list(suspicious_low_variability_features_categ.columns) + ['BsmtHalfBath', 'KitchenAbvGr']):\n    fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n    \n    # Countplot: Display the number of samples for each category.\n    sns.countplot(x=col, data=df_train_copy, ax=axes[0])\n    axes[0].set_title(f'Countplot of {col}')\n    \n    # Barplot: Display the average SalePrice for each category. \n    sns.barplot(x=col, y='SalePrice', data=df_train_copy, ax=axes[1])\n    axes[1].set_title(f'Barplot of {col} vs SalePrice')\n    \n    # Boxplot: Display the SalePrice distribution for each category. \n    sns.boxplot(x=col, y='SalePrice', data=df_train_copy, ax=axes[2])\n    axes[2].set_title(f'Boxplot of {col} vs SalePrice')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:19:33.082517Z","iopub.execute_input":"2023-12-17T17:19:33.08287Z","iopub.status.idle":"2023-12-17T17:20:01.405655Z","shell.execute_reply.started":"2023-12-17T17:19:33.082839Z","shell.execute_reply":"2023-12-17T17:20:01.40442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"suspicious_low_variability_features_numeric = [col for col in list(suspicious_low_variability_features_numeric.columns) if col not in ['BsmtHalfBath', 'KitchenAbvGr']]\n\nfor feature in suspicious_low_variability_features_numeric:\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Violinplot.\n    sns.violinplot(x=df_train_copy[feature], ax=axes[0])\n    axes[0].set_title(f'Violinplot of {feature}')\n    \n    # Scatterplot.\n    sns.scatterplot(x=feature, y='SalePrice', data=df_train_copy, ax=axes[1])\n    axes[1].set_title(f'{feature} vs SalePrice')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:01.407514Z","iopub.execute_input":"2023-12-17T17:20:01.408156Z","iopub.status.idle":"2023-12-17T17:20:05.348592Z","shell.execute_reply.started":"2023-12-17T17:20:01.408122Z","shell.execute_reply":"2023-12-17T17:20:05.347346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a data processing pipeline using existing visualization tools and adding additional visualization as needed.","metadata":{}},{"cell_type":"code","source":"class CustomFeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"A base class with a placeholder fit method for feature engineering transformers.\"\"\"\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        return X\n    \n    \nclass CreateCopy(CustomFeatureEngineer):\n    def transform(self, X, y=None):\n        \"\"\"Return a copy of the DataFrame.\"\"\"\n        return X.copy()\n\n    \nclass HandleMissingValues(CustomFeatureEngineer):\n    def transform(self, X, y=None):\n        \"\"\"Handling missing values for specific columns.\"\"\"\n        # Creating a dictionary with column names and values for filling.\n        fill_values = {\n            'Alley': 'No alley access',\n            'MasVnrType': 'No Masonry',\n            'FireplaceQu': 'No Fireplace',\n            'Fence': 'No Fence',\n            'GarageQual': 'No Garage',\n            'BsmtCond': 'No Basement',\n            'BsmtQual': 'No Basement',\n            'BsmtExposure': 'No Basement',\n            'BsmtFinType1': 'No Basement',\n            'Electrical': 'SBrkr',\n            'GarageType': 'No Garage',\n            'GarageFinish': 'No Garage',\n            'MiscFeature': 'No feature',\n            'BsmtFinType2': 'No Basement'\n        }\n\n        # Filling missing values in the respective columns.\n        X.fillna(value=fill_values, inplace=True)\n\n        return X\n\n    \nclass ChangingEntries(CustomFeatureEngineer):\n    def transform(self, X, y=None):\n        \"\"\"Based on visualization and logic, reorganizing data.\"\"\"\n        def transform_MSZoning(zone):\n            if zone in ['RM']:\n                return 'RM'\n            elif zone in ['FV']:\n                return 'FV'\n            elif zone in ['RL', 'RP']:\n                return 'RL_and_RP'\n            else:\n                return 'Other'\n\n        X['MSZoning'] = X['MSZoning'].apply(transform_MSZoning)\n        \n        X.loc[~(X.LotConfig == 'CulDSac'), 'LotConfig'] = 'Other'\n        X.loc[(X.BldgType == '2FmCon') | (X.BldgType == 'Duplx'), 'BldgType'] = 'MultiFamily'\n        X.loc[~((X.RoofStyle == 'Hip') | (X.RoofStyle == 'Gable')), 'RoofStyle'] = 'Other'\n        \n        X.loc[~((X.ExterCond == 'Fa') | (X.ExterCond == 'Po')), 'ExterCond'] = 'Gd'\n        X.loc[X.ExterCond == 'Po', 'ExterCond'] = 'Fa'\n        \n        X.loc[X.Electrical == 'Mix', 'Electrical'] = 'FuseP'\n        \n        X.loc[X.GarageQual == 'Ex', 'GarageQual'] = 'Gd'\n        X.loc[X.GarageQual == 'Po', 'GarageQual'] = 'No Garage'\n\n        return X\n    \n    \nclass DropUnnecessaryFeatures(CustomFeatureEngineer):\n    def transform(self, X, y=None):\n        \"\"\"Removing due to weak visual differences and significant class imbalance. \n        Also removing features that were used for transformations in prior steps.\"\"\"\n        return X.drop(['PoolQC', 'Utilities', 'Condition2', 'RoofMatl',\n                       'Heating', 'GarageCond', 'BsmtHalfBath',\n                       'KitchenAbvGr'], axis=1)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:05.350127Z","iopub.execute_input":"2023-12-17T17:20:05.350485Z","iopub.status.idle":"2023-12-17T17:20:05.368468Z","shell.execute_reply.started":"2023-12-17T17:20:05.350454Z","shell.execute_reply":"2023-12-17T17:20:05.367243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating and applying a pipeline to obtain the data frame with which I will continue to work.\n\npreprocessing_pipeline = Pipeline([\n    ('create_copy', CreateCopy()),  # Creating a copy\n    ('custom_feature_engineer', CustomFeatureEngineer()),  # Here, numerical and categorical features will be separated.\n    ('handle_missing_values', HandleMissingValues()),  # Handling missing values.\n    ('changing_entries', ChangingEntries()),  # Modifying entries.\n    ('drop_features', DropUnnecessaryFeatures())  # Removing unnecessary features.\n])\n\n# Applying the pipeline.\ndf_transformed = preprocessing_pipeline.fit_transform(df_train)\n\ndf_transformed","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:05.369856Z","iopub.execute_input":"2023-12-17T17:20:05.370372Z","iopub.status.idle":"2023-12-17T17:20:05.436248Z","shell.execute_reply.started":"2023-12-17T17:20:05.370339Z","shell.execute_reply":"2023-12-17T17:20:05.435123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization #2","metadata":{}},{"cell_type":"code","source":"# Visualization of numerical features for making decisions on their processing.\n\nnumeric_features = df_transformed.select_dtypes(include=['int64', 'float64'])\n\nfiltered_features = numeric_features.describe().loc[:, numeric_features.describe().loc['count'] != 1460]\nfiltered_features","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:05.437838Z","iopub.execute_input":"2023-12-17T17:20:05.438239Z","iopub.status.idle":"2023-12-17T17:20:05.597051Z","shell.execute_reply.started":"2023-12-17T17:20:05.438201Z","shell.execute_reply":"2023-12-17T17:20:05.59583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in filtered_features.columns:\n    sns.boxplot(y=col, data=df_transformed)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:05.598497Z","iopub.execute_input":"2023-12-17T17:20:05.598827Z","iopub.status.idle":"2023-12-17T17:20:06.214819Z","shell.execute_reply.started":"2023-12-17T17:20:05.5988Z","shell.execute_reply":"2023-12-17T17:20:06.213392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GarageYrBlt - Filling with the median.\ngarage_median = df_transformed['GarageYrBlt'].median()\ndf_transformed['GarageYrBlt'].fillna(garage_median, inplace=True)\n\n# MasVnrArea - Filling with the median.\nmasvn_median = df_transformed['MasVnrArea'].median()\ndf_transformed['MasVnrArea'].fillna(masvn_median, inplace=True)\n\n# LotFrontage - Truncated mean.\nlot_values = df_transformed['LotFrontage'].dropna()\nlower_bound, upper_bound = np.percentile(lot_values, [2.5, 97.5])\ntruncated_mean = lot_values[(lot_values >= lower_bound) & (lot_values <= upper_bound)].mean()\ndf_transformed['LotFrontage'].fillna(truncated_mean, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:06.216762Z","iopub.execute_input":"2023-12-17T17:20:06.217764Z","iopub.status.idle":"2023-12-17T17:20:06.229989Z","shell.execute_reply.started":"2023-12-17T17:20:06.217724Z","shell.execute_reply":"2023-12-17T17:20:06.228816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's build a correlation table.\n\nnumeric_features.corr()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:06.231355Z","iopub.execute_input":"2023-12-17T17:20:06.2317Z","iopub.status.idle":"2023-12-17T17:20:06.308659Z","shell.execute_reply.started":"2023-12-17T17:20:06.23167Z","shell.execute_reply":"2023-12-17T17:20:06.30783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Functions to find the most correlated features.\n\ndef get_redundant_pairs(df):\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Absolute Correlations\")\nprint(get_top_abs_correlations(numeric_features, 10))","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:06.309916Z","iopub.execute_input":"2023-12-17T17:20:06.310498Z","iopub.status.idle":"2023-12-17T17:20:06.348802Z","shell.execute_reply.started":"2023-12-17T17:20:06.310466Z","shell.execute_reply":"2023-12-17T17:20:06.347652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Based on the correlation analysis, let's remove a few features.\n\ndf_transformed = df_transformed.drop(['GarageCars', 'GarageYrBlt', 'TotRmsAbvGrd',\n                                      'TotalBsmtSF', 'OverallQual'], axis=1)\ndf_transformed","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:06.350516Z","iopub.execute_input":"2023-12-17T17:20:06.351616Z","iopub.status.idle":"2023-12-17T17:20:06.385447Z","shell.execute_reply.started":"2023-12-17T17:20:06.351571Z","shell.execute_reply":"2023-12-17T17:20:06.384595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = df_transformed.select_dtypes(include=['object'])\n\nfiltered_categorical_features = categorical_features.describe().loc[:, categorical_features.describe().loc['count'] != 1460]\nfiltered_categorical_features","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:06.389924Z","iopub.execute_input":"2023-12-17T17:20:06.390459Z","iopub.status.idle":"2023-12-17T17:20:06.518846Z","shell.execute_reply.started":"2023-12-17T17:20:06.39043Z","shell.execute_reply":"2023-12-17T17:20:06.517984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a dictionary with column names and values for filling.\nfill_values = {\n    'BsmtQual': 'No Basement',\n    'BsmtExposure': 'No Basement',\n    'BsmtFinType1': 'No Basement',\n    'Electrical': 'SBrkr',\n    'GarageType': 'No Garage',\n    'GarageFinish': 'No Garage'\n}\n\n# Filling missing values in the respective columns.\ndf_transformed.fillna(value=fill_values, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:06.520072Z","iopub.execute_input":"2023-12-17T17:20:06.520569Z","iopub.status.idle":"2023-12-17T17:20:06.530699Z","shell.execute_reply.started":"2023-12-17T17:20:06.52054Z","shell.execute_reply":"2023-12-17T17:20:06.529405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = df_transformed.select_dtypes(include=['object'])\n\nfor feature in categorical_features.columns:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n    \n    # Countplot: Display the number of samples for each category.\n    ax1 = sns.countplot(x=feature, data=df_transformed, ax=axes[0])\n    axes[0].set_title(f'Countplot of {feature}')\n    axes[0].set_xlabel(feature)\n    axes[0].set_ylabel('Count')\n    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)  \n    \n    # Barplot: Display the average SalePrice for each category.\n    ax2 = sns.barplot(x=feature, y=\"SalePrice\", data=df_transformed, ax=axes[1])\n    axes[1].set_title(f'Barplot of {feature} vs SalePrice')\n    axes[1].set_xlabel(feature)\n    axes[1].set_ylabel('SalePrice')\n    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45) \n    \n    # Boxplot: Display the SalePrice distribution for each category.\n    ax3 = sns.boxplot(x=feature, y='SalePrice', data=df_transformed, ax=axes[2])\n    axes[2].set_title(f'Boxplot of {feature} vs SalePrice')\n    axes[2].set_xlabel(feature)\n    axes[2].set_ylabel('SalePrice')\n    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45) \n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:06.532536Z","iopub.execute_input":"2023-12-17T17:20:06.53304Z","iopub.status.idle":"2023-12-17T17:20:50.788452Z","shell.execute_reply.started":"2023-12-17T17:20:06.532997Z","shell.execute_reply":"2023-12-17T17:20:50.78714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the remaining data processing classes and forming the final pipeline before model training.","metadata":{}},{"cell_type":"code","source":"class HandleNumericFeatures(CustomFeatureEngineer):\n    def transform(self, X, y=None):\n        \"\"\"Applying transformations to numerical features\"\"\"        \n        # GarageYrBlt - Filling with the median.\n        garage_median = X['GarageYrBlt'].median()\n        X['GarageYrBlt'].fillna(garage_median, inplace=True)\n\n        # MasVnrArea - Filling with the median.\n        masvn_median = X['MasVnrArea'].median()\n        X['MasVnrArea'].fillna(masvn_median, inplace=True)\n\n        # LotFrontage - Truncated mean.\n        lot_values = X['LotFrontage'].dropna()\n        lower_bound, upper_bound = np.percentile(lot_values, [2.5, 97.5])\n        truncated_mean = lot_values[(lot_values >= lower_bound) & (lot_values <= upper_bound)].mean()\n        X['LotFrontage'].fillna(truncated_mean, inplace=True)\n        \n        # Previously, I removed these features based on correlation assessment,\n        # but after some experiments, I realized it's better to keep them.\n        # X = X.drop(['GarageCars', 'TotRmsAbvGrd',\n        #            'TotalBsmtSF', 'OverallQual', 'GarageYrBlt'], axis=1)\n        return X","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:50.790006Z","iopub.execute_input":"2023-12-17T17:20:50.7904Z","iopub.status.idle":"2023-12-17T17:20:50.800673Z","shell.execute_reply.started":"2023-12-17T17:20:50.790364Z","shell.execute_reply":"2023-12-17T17:20:50.799756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HandleCategoricalFeatures(CustomFeatureEngineer):\n    def __init__(self, random_state=None):\n        self.columns_to_label_encode = ['MSZoning', 'Alley', 'LotConfig', 'BldgType', 'HouseStyle', 'RoofStyle',\n                                        'MasVnrType', 'Foundation', 'CentralAir', 'Electrical', 'GarageFinish',\n                                        'PavedDrive', 'Fence', 'GarageType', 'SaleCondition',\n                                        'MiscFeature', 'Street', 'Condition1', 'SaleType']\n        self.label_encoders = {}  # Dictionary for storing encoders.\n        for col in self.columns_to_label_encode:\n            self.label_encoders[col] = LabelEncoder()\n        \n        self.ordinal_encoder = OrdinalEncoder()\n        self.columns_to_ordinal_encode = ['LotShape', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n                                          'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'KitchenQual',\n                                          'FireplaceQu', 'GarageQual', 'LandContour', 'LandSlope',\n                                          'BsmtFinType2', 'Functional']\n        self.ordinal_mappings = {\n            'LotShape': {\n                'Reg': 0,\n                'IR1': 1,\n                'IR2': 2, \n                'IR3': 3  \n            },\n            'ExterQual': {\n                'Ex': 0,\n                'Gd': 1,\n                'TA': 2,\n                'Fa': 3,\n                'Po': 4\n            },\n            'ExterCond': {\n                'Gd': 0,\n                'Fa': 1\n            },\n            'BsmtQual': {\n                'Ex': 0,\n                'Gd': 1,\n                'TA': 2,\n                'Fa': 3,\n                'Po': 4,\n                'No Basement': 5\n            },\n            'BsmtCond': {\n                'Ex': 0,\n                'Gd': 1,\n                'TA': 2,\n                'Fa': 3,\n                'Po': 4,\n                'No Basement': 5\n            },\n            'BsmtExposure': {\n                'Gd': 0,\n                'Av': 1,\n                'Mn': 2,\n                'No': 3,\n                'No Basement': 4\n            },\n            'BsmtFinType1': {\n                'GLQ': 0,\n                'ALQ': 1,\n                'BLQ': 2,\n                'Rec': 3,\n                'LwQ': 4,\n                'Unf': 5,\n                'No Basement': 6\n            },\n            'HeatingQC': {\n                'Ex': 0,\n                'Gd': 1,\n                'TA': 2,\n                'Fa': 3,\n                'Po': 4\n            },\n            'KitchenQual': {\n                'Ex': 0,\n                'Gd': 1,\n                'TA': 2,\n                'Fa': 3,\n                'Po': 4\n            },\n            'FireplaceQu': {\n                'Ex': 0,\n                'Gd': 1,\n                'TA': 2,\n                'Fa': 3,\n                'Po': 4,\n                'No Fireplace': 5\n            },\n            'GarageQual': {\n                'Gd': 0,\n                'TA': 1,\n                'Fa': 2,\n                'No Garage': 3\n            },\n            'LandContour': {\n                'Lvl': 0,\n                'Bnk': 1,\n                'HLS': 2,\n                'Low': 3\n            },\n            'LandSlope': {\n                'Gtl': 0,\n                'Mod': 1,\n                'Sev': 2\n            },\n            'BsmtFinType2': {\n                'GLQ': 0,\n                'ALQ': 1,\n                'BLQ': 2,\n                'Rec': 3,\n                'LwQ': 4,\n                'Unf': 5,\n                'No Basement': 6\n            },\n            'Functional': {\n                'Typ': 0,\n                'Min1': 1,\n                'Min2': 2,\n                'Mod': 3,\n                'Maj1': 4,\n                'Maj2': 5,\n                'Sev': 6,\n                'Sal': 7\n            }\n        }\n        \n        # Add Target Encoding.\n        self.columns_to_target_encode = ['Neighborhood', 'Exterior1st', 'Exterior2nd']\n        self.target_encodings = {}\n        self.global_mean = 0\n        \n        # Fix the random_state.\n        self.random_state = random_state\n        self.random_generator = np.random.RandomState(random_state)\n    \n    def fit(self, X, y=None):\n        # Perform label encoding at the fit stage to preserve category information.\n        for col in self.columns_to_label_encode:\n            self.label_encoders[col].fit(X[col])\n        \n        # The average value of the target variable.\n        self.global_mean = y.mean()\n        \n        # Calculate Target Encoding for each category.\n        for column in self.columns_to_target_encode:\n            aggregated = X.groupby(column).agg({y.name: 'mean'})\n            self.target_encodings[column] = aggregated[y.name].to_dict()\n            \n        return self\n    \n    def transform(self, X, y=None):\n        \"\"\"Apply transformations to categorical features\"\"\" \n        # label encoding.\n        for col in self.columns_to_label_encode:\n            X[col] = X[col].map(lambda s: self.label_encoders[col].transform([s])[0] if s in self.label_encoders[col].classes_ else 15)\n        \n        # Ordinal encoding.\n        for column in self.columns_to_ordinal_encode:\n            X[column] = X[column].map(self.ordinal_mappings[column])\n            \n        # Target Encoding with regularization.\n        for column in self.columns_to_target_encode:\n            # Add random noise to encoded values using a generator with a fixed state.\n            noise = self.random_generator.normal(0, 0.01, size=X[column].shape)\n            X[column] = X[column].map(self.target_encodings[column]).fillna(self.global_mean) + noise\n\n\n        return X","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:50.802153Z","iopub.execute_input":"2023-12-17T17:20:50.802783Z","iopub.status.idle":"2023-12-17T17:20:50.830465Z","shell.execute_reply.started":"2023-12-17T17:20:50.802752Z","shell.execute_reply":"2023-12-17T17:20:50.829072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating and applying a pipeline to obtain the data frame with which I will continue to work.\n\npreprocessing_pipeline = Pipeline([\n    ('create_copy', CreateCopy()),  # Creating a copy.\n    ('custom_feature_engineer', CustomFeatureEngineer()),  # Placeholder for the fit method.\n    ('handle_missing_values', HandleMissingValues()),  # Handling missing values.\n    ('changing_entries', ChangingEntries()),  # Modifying entries.\n    ('drop_features', DropUnnecessaryFeatures()),  # Removing unnecessary features.\n    ('numeric_feature_handler', HandleNumericFeatures()),  # Processing numerical features.\n    ('categorical_feature_handler', HandleCategoricalFeatures(random_state=100))  # Processing categorical features.\n])\n\n# Applying the pipeline.\ndf_train_end = preprocessing_pipeline.fit_transform(df_train, \n                                                    df_train.SalePrice)\n\ndf_train_end","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:50.832456Z","iopub.execute_input":"2023-12-17T17:20:50.834146Z","iopub.status.idle":"2023-12-17T17:20:52.935871Z","shell.execute_reply.started":"2023-12-17T17:20:50.834111Z","shell.execute_reply":"2023-12-17T17:20:52.934622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_end = preprocessing_pipeline.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:52.937262Z","iopub.execute_input":"2023-12-17T17:20:52.937587Z","iopub.status.idle":"2023-12-17T17:20:55.0297Z","shell.execute_reply.started":"2023-12-17T17:20:52.937558Z","shell.execute_reply":"2023-12-17T17:20:55.028524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There were 6 NaN values found in the test data. For simplicity, I will fill them with the median values.\n\nmedians = df_test_end.median()\n\ndf_test_end = df_test_end.fillna(medians)\ndf_test_end.isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:55.03092Z","iopub.execute_input":"2023-12-17T17:20:55.031379Z","iopub.status.idle":"2023-12-17T17:20:55.083442Z","shell.execute_reply.started":"2023-12-17T17:20:55.031337Z","shell.execute_reply":"2023-12-17T17:20:55.082424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating new features","metadata":{}},{"cell_type":"markdown","source":"Here, I am creating new features based on the existing data and adding new features from an additional dataset with macro indicators. I chose these particular features to add based on experiments that will not be shown in this notebook.","metadata":{}},{"cell_type":"code","source":"# Loading an additional dataset, which I created based on the year of property sale and geographical location.\ndf_new = pd.read_csv('/kaggle/input/enhancedhousingmarketdata/EnhancedHousingMarketData.csv')\ndf_new.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:55.084736Z","iopub.execute_input":"2023-12-17T17:20:55.085435Z","iopub.status.idle":"2023-12-17T17:20:55.119737Z","shell.execute_reply.started":"2023-12-17T17:20:55.085404Z","shell.execute_reply":"2023-12-17T17:20:55.118308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding new features to the original dataset.\ndf_train_end.rename(columns={'YrSold': 'Year', 'MoSold': 'Month'}, inplace=True)\ndf_test_end.rename(columns={'YrSold': 'Year', 'MoSold': 'Month'}, inplace=True)\n\ndf_train_end = df_train_end.merge(df_new[['Year', 'Month', 'AverageWeeklyWagePrivate', 'TotalRealGDP']], on=['Year', 'Month'], how='left')\ndf_test_end = df_test_end.merge(df_new[['Year', 'Month', 'AverageWeeklyWagePrivate', 'TotalRealGDP']], on=['Year', 'Month'], how='left')\n\ndf_train_end.rename(columns={'Year': 'YrSold', 'Month': 'MoSold'}, inplace=True)\ndf_test_end.rename(columns={'Year': 'YrSold', 'Month': 'MoSold'}, inplace=True)\ndf_train_end","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:55.121234Z","iopub.execute_input":"2023-12-17T17:20:55.121596Z","iopub.status.idle":"2023-12-17T17:20:55.174763Z","shell.execute_reply.started":"2023-12-17T17:20:55.121564Z","shell.execute_reply":"2023-12-17T17:20:55.173357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AgeAtSale: Year of sale (YrSold) minus the year of construction (YearBuilt). This feature reflects the age of the house at the time of sale.\ndf_train_end['AgeAtSale'] = df_train_end['YrSold'] - df_train_end['YearBuilt']\n\n#YearsSinceRemodel: Year of sale (YrSold) minus the year of the last renovation (YearRemodAdd). Shows how many years have passed since the last renovation.\ndf_train_end['YearsSinceRemodel'] = df_train_end['YrSold'] - df_train_end['YearRemodAdd']\n\n#TotalSqFt: The sum of the areas of all floors (1stFlrSF, 2ndFlrSF) plus the total basement area (TotalBsmtSF). This gives the total living area.\ndf_train_end['TotalSqFt'] = df_train_end['1stFlrSF'] + df_train_end['2ndFlrSF'] + df_train_end['TotalBsmtSF']\n\n#Bathrooms: The sum of all bathrooms (FullBath + 0.5 * HalfBath + BsmtFullBath + 0.5 * BsmtHalfBath). This is the total number of bathrooms in the house.\ndf_train_end['Bathrooms'] = df_train_end['FullBath'] + (0.5 * df_train_end['HalfBath']) + df_train_end['BsmtFullBath'] + (0.5 * df_train['BsmtHalfBath'])\n\n#TotalPorchSF: The sum of all types of porches (OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch). Gives the total porch area.\ndf_train_end['TotalPorchSF'] = df_train_end['OpenPorchSF'] + df_train_end['EnclosedPorch'] + df_train_end['3SsnPorch'] + df_train_end['ScreenPorch']\n\n#PropertyShape: A categorical feature that combines LotShape and LandContour, can provide a more detailed view of the geometry and topography of the property.\ndf_train_end['PropertyShape'] = df_train_end['LotShape'] + df_train_end['LandContour']\n\n#OverallQuality&Condition: A combination of overall quality (OverallQual) and overall condition (OverallCond) as a sum.\ndf_train_end['OverallQuality&Condition'] = df_train_end['OverallQual'] + df_train_end['OverallCond']\n\n#TotalBsmtFinSF: The sum of BsmtFinSF1 and BsmtFinSF2, giving the total finished basement area.\ndf_train_end['TotalBsmtFinSF'] = df_train_end['BsmtFinSF1'] + df_train_end['BsmtFinSF2']\n\n#NeighborhoodQuality: A combination of Neighborhood and OverallQual to assess the quality of the property in the context of its area.\ndf_train_end['NeighborhoodQuality'] = (df_train_end['Neighborhood'] * df_train_end['OverallQual']) * 0.1\n\n#FrontageToAreaRatio: The ratio of street frontage in linear feet (LotFrontage) to the lot size (LotArea). This feature can reflect the proportionality of the facade to the size of the lot.\ndf_train_end['FrontageToAreaRatio'] = df_train_end['LotFrontage'] / df_train_end['LotArea']\n\n#TotalLivArea: The total living area, including the basement (GrLivArea + TotalBsmtSF). This provides a more comprehensive view of the available living space.\ndf_train_end['TotalLivArea'] = df_train_end['GrLivArea'] + df_train_end['TotalBsmtSF']\n\n#RoomAverageSize: The average room size, based on the total living area (GrLivArea) and the total number of rooms (TotRmsAbvGrd).\ndf_train_end['RoomAverageSize'] = df_train_end['GrLivArea'] / df_train_end['TotRmsAbvGrd']\n\n#AgeOfGarage: Year of sale (YrSold) minus the year the garage was built (GarageYrBlt). Shows the age of the garage at the time of sale.\ndf_train_end['AgeOfGarage'] = df_train_end['YrSold'] - df_train_end['GarageYrBlt']\n\n#TotalOutdoorArea: The sum of all outdoor areas (WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea).\ndf_train_end['TotalOutdoorArea'] = df_train_end['WoodDeckSF'] + df_train_end['OpenPorchSF'] + df_train_end['EnclosedPorch'] + df_train_end['3SsnPorch'] + df_train_end['ScreenPorch'] + df_train_end['PoolArea']\n\n#SeasonSold: The month of sale (MoSold) converted into the season of the year, to capture seasonal trends.\n#Function to convert month into season\ndef map_month_to_season(month):\n    if month in [3, 4, 5]:\n        return 1\n    elif month in [6, 7, 8]:\n        return 2\n    elif month in [9, 10, 11]:\n        return 3\n    else:\n        return 4\n\ndf_train_end['SeasonSold'] = df_train_end['MoSold'].apply(map_month_to_season)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:55.176632Z","iopub.execute_input":"2023-12-17T17:20:55.1775Z","iopub.status.idle":"2023-12-17T17:20:55.209783Z","shell.execute_reply.started":"2023-12-17T17:20:55.177458Z","shell.execute_reply":"2023-12-17T17:20:55.208613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AgeAtSale: Year of sale (YrSold) minus the year of construction (YearBuilt). This feature reflects the age of the house at the time of sale.\ndf_test_end['AgeAtSale'] = df_test_end['YrSold'] - df_test_end['YearBuilt']\n\n#YearsSinceRemodel: Year of sale (YrSold) minus the year of the last renovation (YearRemodAdd). Shows how many years have passed since the last renovation.\ndf_test_end['YearsSinceRemodel'] = df_test_end['YrSold'] - df_test_end['YearRemodAdd']\n\n#TotalSqFt: The sum of the areas of all floors (1stFlrSF, 2ndFlrSF) plus the total basement area (TotalBsmtSF). This gives the total living area.\ndf_test_end['TotalSqFt'] = df_test_end['1stFlrSF'] + df_test_end['2ndFlrSF'] + df_test_end['TotalBsmtSF']\n\n#Bathrooms: The sum of all bathrooms (FullBath + 0.5 * HalfBath + BsmtFullBath + 0.5 * BsmtHalfBath). This is the total number of bathrooms in the house.\ndf_test_end['Bathrooms'] = df_test_end['FullBath'] + (0.5 * df_test_end['HalfBath']) + df_test_end['BsmtFullBath'] + (0.5 * df_test['BsmtHalfBath'])\n\n#TotalPorchSF: The sum of all types of porches (OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch). Gives the total porch area.\ndf_test_end['TotalPorchSF'] = df_test_end['OpenPorchSF'] + df_test_end['EnclosedPorch'] + df_test_end['3SsnPorch'] + df_test_end['ScreenPorch']\n\n#PropertyShape: A categorical feature that combines LotShape and LandContour, can provide a more detailed view of the geometry and topography of the property.\ndf_test_end['PropertyShape'] = df_test_end['LotShape'] + df_test_end['LandContour']\n\n#OverallQuality&Condition: A combination of overall quality (OverallQual) and overall condition (OverallCond) as a sum.\ndf_test_end['OverallQuality&Condition'] = df_test_end['OverallQual'] + df_test_end['OverallCond']\n\n#TotalBsmtFinSF: The sum of BsmtFinSF1 and BsmtFinSF2, giving the total finished basement area.\ndf_test_end['TotalBsmtFinSF'] = df_test_end['BsmtFinSF1'] + df_test_end['BsmtFinSF2']\n\n#NeighborhoodQuality: A combination of Neighborhood and OverallQual to assess the quality of the property in the context of its area.\ndf_test_end['NeighborhoodQuality'] = (df_test_end['Neighborhood'] * df_test_end['OverallQual']) * 0.1\n\n#FrontageToAreaRatio: The ratio of street frontage in linear feet (LotFrontage) to the lot size (LotArea). This feature can reflect the proportionality of the facade to the size of the lot.\ndf_test_end['FrontageToAreaRatio'] = df_test_end['LotFrontage'] / df_test_end['LotArea']\n\n#TotalLivArea: The total living area, including the basement (GrLivArea + TotalBsmtSF). This provides a more comprehensive view of the available living space.\ndf_test_end['TotalLivArea'] = df_test_end['GrLivArea'] + df_test_end['TotalBsmtSF']\n\n#RoomAverageSize: The average room size, based on the total living area (GrLivArea) and the total number of rooms (TotRmsAbvGrd).\ndf_test_end['RoomAverageSize'] = df_test_end['GrLivArea'] / df_test_end['TotRmsAbvGrd']\n\n#AgeOfGarage: Year of sale (YrSold) minus the year the garage was built (GarageYrBlt). Shows the age of the garage at the time of sale.\ndf_test_end['AgeOfGarage'] = df_test_end['YrSold'] - df_test_end['GarageYrBlt']\n\n#TotalOutdoorArea: The sum of all outdoor areas (WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea).\ndf_test_end['TotalOutdoorArea'] = df_test_end['WoodDeckSF'] + df_test_end['OpenPorchSF'] + df_test_end['EnclosedPorch'] + df_test_end['3SsnPorch'] + df_test_end['ScreenPorch'] + df_test_end['PoolArea']\n\n#SeasonSold: The month of sale (MoSold) converted into the season of the year, to capture seasonal trends.\n#Function to convert month into season\ndef map_month_to_season(month):\n    if month in [3, 4, 5]:\n        return 1\n    elif month in [6, 7, 8]:\n        return 2\n    elif month in [9, 10, 11]:\n        return 3\n    else:\n        return 4\n\ndf_test_end['SeasonSold'] = df_test_end['MoSold'].apply(map_month_to_season)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:55.211813Z","iopub.execute_input":"2023-12-17T17:20:55.212301Z","iopub.status.idle":"2023-12-17T17:20:55.246965Z","shell.execute_reply.started":"2023-12-17T17:20:55.212261Z","shell.execute_reply":"2023-12-17T17:20:55.245779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model and predictions","metadata":{}},{"cell_type":"code","source":"def rmsle(y_true, y_pred):\n    if (y_true < 0).any() or (y_pred < 0).any():\n        print(f\"Negative values found: y_true min = {y_true.min()}, y_pred min = {y_pred.min()}\")\n        \n    min_positive = y_pred[y_pred > 0].min()\n    y_pred[y_pred <= 0] = min_positive\n    \n    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n\nrmsle_scorer = make_scorer(rmsle, greater_is_better=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:55.248461Z","iopub.execute_input":"2023-12-17T17:20:55.248964Z","iopub.status.idle":"2023-12-17T17:20:55.263444Z","shell.execute_reply.started":"2023-12-17T17:20:55.248925Z","shell.execute_reply":"2023-12-17T17:20:55.262492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBRegresor","metadata":{}},{"cell_type":"code","source":"X = df_train_end.drop(columns=['SalePrice'], axis=1)\ny = df_train_end['SalePrice']\n\ndef anomalies(X):\n\n    # Creating an Isolation Forest instance\n    iso_forest = IsolationForest(max_samples=0.7, contamination=0.015, \n                                 bootstrap=True, n_jobs=-1, random_state=100)\n    \n    iso_forest.fit(X)\n    # Obtaining anomaly labels for the training dataset (-1 for anomalies and 1 for normal points)\n    train_outliers = iso_forest.predict(X)\n    \n    return train_outliers\n\n# Identifying the indices of anomalies\nindex_anomalies = anomalies(X)\n\n# Filtering out the anomalies from the training set based on the index\nX = X[index_anomalies == 1]\ny = y[index_anomalies == 1]\n\n# It's important to ensure that the indices of X_train and y_train still match after filtering\nassert X.index.equals(y.index), \"Indices of X_train and y_train do not match after filtering anomalies.\"\n\nmodel = XGBRegressor(n_estimators=1250,\n                     learning_rate=0.03,\n                     min_child_weight=2,\n                     subsample=0.3,\n                     colsample_bytree=0.2,\n                     max_depth=4, \n                     random_state=100,\n                     reg_alpha=2.5,\n                     num_parallel_tree=6)\n\nmodel.fit(X, y)\n\ndf_test['SalePrice'] = model.predict(df_test_end.drop(['Id'], axis=1))\ndf_test[['Id', 'SalePrice']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:20:55.264758Z","iopub.execute_input":"2023-12-17T17:20:55.266073Z","iopub.status.idle":"2023-12-17T17:21:04.375007Z","shell.execute_reply.started":"2023-12-17T17:20:55.266039Z","shell.execute_reply":"2023-12-17T17:21:04.374077Z"},"trusted":true},"execution_count":null,"outputs":[]}]}